{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16e2a45a-659a-4de3-bbd1-204b1da5456c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2105cf9-4115-45cc-a055-33e02c9340e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import copernicusmarine\n",
    "import dask\n",
    "from datetime import datetime, timedelta\n",
    "import geopandas as gpd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterio.features import geometry_mask\n",
    "import rioxarray as rxr\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely.geometry import mapping, Point\n",
    "from scipy.spatial import cKDTree\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "\n",
    "os.chdir(\"/media/marieke/Shared/Chap-1/Model/Scripts/Chap_1_2018-2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15621d65-5f08-4e38-be69-f94ffa2d7949",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Get Copernicus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "57932f92-d636-48f7-aff3-aa68fa91c962",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-10-17T10:53:14Z - Selected dataset version: \"202311\"\n",
      "INFO - 2025-10-17T10:53:14Z - Selected dataset part: \"default\"\n",
      "INFO - 2025-10-17T10:53:14Z - Downloading Copernicus Marine data requires a Copernicus Marine username and password, sign up for free at: https://data.marine.copernicus.eu/register\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copernicus Marine username:Abort\n"
     ]
    }
   ],
   "source": [
    "# Set parameters\n",
    "data_request = {\n",
    "   \"dataset_id\" : \"cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D\",\n",
    "   \"longitude\" : [3, 9.65], \n",
    "   \"latitude\" : [41.2, 43.5],\n",
    "   \"time\" : [\"2013-01-01\", \"2025-01-01\"],\n",
    "   \"variables\" : [\"CHL\"]\n",
    "}\n",
    "\n",
    "# Load xarray dataset\n",
    "chl = copernicusmarine.open_dataset(\n",
    "    dataset_id = data_request[\"dataset_id\"],\n",
    "    minimum_longitude = data_request[\"longitude\"][0],\n",
    "    maximum_longitude = data_request[\"longitude\"][1],\n",
    "    minimum_latitude = data_request[\"latitude\"][0],\n",
    "    maximum_latitude = data_request[\"latitude\"][1],\n",
    "    start_datetime = data_request[\"time\"][0],\n",
    "    end_datetime = data_request[\"time\"][1],\n",
    "    variables = data_request[\"variables\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "282c7a84-63a3-4436-b4a4-4acabdab8516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to NCDF \n",
    "chl.to_netcdf(\"./data/raw_data/predictors/Chl/cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D_20130101-20250101.nc\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d22960e-0a76-4e9b-945f-49cb6ba7c83c",
   "metadata": {},
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a801a-2fa1-441f-919b-ac54c9ea78bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff0e6d91-a234-4d3c-af71-98a23bc15ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(date, time_step):\n",
    "    \"\"\"\n",
    "    Calculate the range of dates for a given time step relative to the provided date.\n",
    "    \"\"\"\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    if isinstance(date, str):\n",
    "        date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "\n",
    "    end_date = date - timedelta(days=1)\n",
    "\n",
    "    time_deltas = {\n",
    "        'day': 1,\n",
    "        'week': 7,\n",
    "        'month': 30,\n",
    "        'year': 365,\n",
    "        '5years': 5 * 365 + 1,\n",
    "    }\n",
    "\n",
    "    if time_step not in time_deltas:\n",
    "        raise ValueError(\"Unsupported time step. Choose from 'day', 'week', 'month', 'year', or '5years'.\")\n",
    "\n",
    "    start_date = date - timedelta(days=time_deltas[time_step])\n",
    "    return start_date, end_date\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_stats(data_array, shape_geometry, max_buffer_distance=0, step=0.01):\n",
    "    \"\"\"\n",
    "    Compute the mean, min, and max of valid points (non-NaN) within the given geometry using `.clip`.\n",
    "    Expand the search radius if no valid points exist.\n",
    "    \"\"\"\n",
    "    current_buffer_distance = 0\n",
    "\n",
    "    while current_buffer_distance <= max_buffer_distance:\n",
    "        search_geometry = shape_geometry.buffer(current_buffer_distance) if current_buffer_distance > 0 else shape_geometry\n",
    "\n",
    "        try:\n",
    "            clipped_data = data_array.rio.clip([mapping(search_geometry)], crs=\"EPSG:4326\", drop=True)\n",
    "            if clipped_data.count().item() > 0:\n",
    "                return (\n",
    "                    clipped_data.mean().item(),\n",
    "                    clipped_data.min().item(),\n",
    "                    clipped_data.max().item(),\n",
    "                    current_buffer_distance\n",
    "                )\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\n",
    "        current_buffer_distance += step\n",
    "\n",
    "    return None, None, None, max_buffer_distance\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def open_nc(shape_geometry, date, netcdf_path, variable=\"CHL\"):\n",
    "    \"\"\"\n",
    "    Compute CHL statistics for a given geometry and date using a netCDF file.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    try:\n",
    "        if isinstance(date, str):\n",
    "            date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "\n",
    "        ds = xr.open_dataset(netcdf_path)\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "        target_date = date - timedelta(days=1)\n",
    "        time_steps = [\"day\", \"week\", \"month\", \"year\", \"5years\"]\n",
    "        date_ranges = {label: get_dates(date, label) for label in time_steps}\n",
    "\n",
    "        for label, (start_date, end_date) in date_ranges.items():\n",
    "            ds_time_range = ds.sel(time=slice(start_date, end_date))\n",
    "\n",
    "            if ds_time_range.time.size == 0:\n",
    "                results[label] = (None, None, None, 0)\n",
    "                continue\n",
    "\n",
    "            chl_data = ds_time_range[variable]\n",
    "            empty_days = sum(chl_data.sel(time=t).isnull().all().item() for t in chl_data.time)\n",
    "            valid_data = chl_data.dropna(dim=\"time\", how=\"all\")\n",
    "\n",
    "            if valid_data.size > 0:\n",
    "                mean_val, min_val, max_val, max_search_dist = compute_stats(\n",
    "                    valid_data, shape_geometry, max_buffer_distance=0.1, step=0.01\n",
    "                )\n",
    "                results[label] = (mean_val, min_val, max_val, empty_days)\n",
    "            else:\n",
    "                results[label] = (None, None, None, empty_days)\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing shape with target date: {date}: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def process_geojson(geojson_path, netcdf_path, output_path, variable=\"CHL\"):\n",
    "    \"\"\"\n",
    "    Process the GeoJSON file and compute statistics for each shape using a netCDF file.\n",
    "    \"\"\"\n",
    "    shapes = gpd.read_file(geojson_path)\n",
    "    shapes = shapes.set_crs(\"EPSG:4326\", allow_override=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for _, row in tqdm(shapes.iterrows(), total=shapes.shape[0], desc=\"Processing shapes\"):\n",
    "        shape_geometry = row.geometry\n",
    "        date = row[\"date\"]\n",
    "        polygon_id = row.get(\"spygn_c\", None)\n",
    "\n",
    "        chl_stats = open_nc(shape_geometry, date, netcdf_path, variable)\n",
    "\n",
    "        result_entry = {\"id_spygen\": polygon_id}\n",
    "        for label, (mean, min_val, max_val, empty_days) in chl_stats.items():\n",
    "            result_entry[f\"Cop_CHL_{label}_mean\"] = mean\n",
    "            result_entry[f\"Cop_CHL_{label}_min\"] = min_val\n",
    "            result_entry[f\"Cop_CHL_{label}_max\"] = max_val\n",
    "            result_entry[f\"Cop_CHL_{label}_empty_days\"] = empty_days\n",
    "\n",
    "        results.append(result_entry)\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038df6f-cd89-42fc-9859-2125965fb734",
   "metadata": {},
   "source": [
    "## Run extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b984b43-db14-4d36-b8aa-e2a61ac57cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoJSON file saved to ./data/processed_data/eDNA/mtdt_5.geojson\n"
     ]
    }
   ],
   "source": [
    "# 17/10/2025 : Extract CHL from cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D \n",
    "\n",
    "# 1. Convert .shp to .geojson \n",
    "# Load the file with buffer for extraction\n",
    "gdf = gpd.read_file(\"./data/processed_data/eDNA/mtdt_5.gpkg\")\n",
    "\n",
    "# Save as GeoJSON\n",
    "geojson_path = \"./data/processed_data/eDNA/mtdt_5.geojson\"\n",
    "gdf.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"GeoJSON file saved to {geojson_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b64558-36ca-4679-9239-9c6920d5a493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing shapes:   8%|█▊                     | 61/788 [03:15<40:32,  3.35s/it]"
     ]
    }
   ],
   "source": [
    "# 2. Make extraction (using Fct 4 and max buffer size = 0)\n",
    "\n",
    "geojson_path=\"./data/processed_data/eDNA/mtdt_5.geojson\"\n",
    "netcdf_path=\"./data/raw_data/predictors/Chl/cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D_20130101-20250101.nc\"\n",
    "output_path=\"./data/processed_data/predictors/Extracted_Predictors/mtdt_5_CHL.csv\"\n",
    "\n",
    "\n",
    "process_geojson(\n",
    "    geojson_path=geojson_path,\n",
    "    netcdf_path=netcdf_path,\n",
    "    output_path=output_path,\n",
    "    variable=\"CHL\"  \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
