{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f1f627",
   "metadata": {},
   "source": [
    "## Extraction des variables température, salinité et force du vent sur la zone de la corse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732e2f8d",
   "metadata": {},
   "source": [
    "### 1. Extraction des variables TEMP et SAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37eb442a",
   "metadata": {},
   "source": [
    "#### Extraction 24H en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd4648c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction Temp & Sal sur 24h: 100%|██████████| 70/70 [1:44:36<00:00, 89.66s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_period(dt, base_folder, hours=24):\n",
    "    start_dt = dt - timedelta(hours=hours)\n",
    "    files = []\n",
    "\n",
    "    for year in range(start_dt.year, dt.year + 1):\n",
    "        year_folder = os.path.join(base_folder, str(year))\n",
    "        pattern = os.path.join(year_folder, \"MARC_F2-MARS3D-MENOR1200_????????T????Z.nc\")\n",
    "        candidates = glob.glob(pattern)\n",
    "\n",
    "        def extract_datetime_from_filename(f):\n",
    "            match = re.search(r\"_(\\d{8}T\\d{4})Z\\.nc$\", f)\n",
    "            if not match:\n",
    "                return None\n",
    "            return datetime.strptime(match.group(1), \"%Y%m%dT%H%M\")\n",
    "\n",
    "        for f in candidates:\n",
    "            f_dt = extract_datetime_from_filename(f)\n",
    "            if f_dt and start_dt <= f_dt <= dt:\n",
    "                files.append((f, f_dt))\n",
    "\n",
    "    files.sort(key=lambda x: x[1])\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"Aucun fichier trouvé entre {start_dt} et {dt}\")\n",
    "\n",
    "    return [f for f, _ in files]\n",
    "\n",
    "\n",
    "def get_temp_sal_for_poly(poly, depth_sampling, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    bathy = ds['H0']\n",
    "    temp = ds['TEMP']\n",
    "    sal = ds['SAL']\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(bathy.rio.crs).iloc[0]\n",
    "\n",
    "    transform = bathy.rio.transform()\n",
    "    height, width = bathy.shape\n",
    "\n",
    "    coords = []\n",
    "    bathy_vals = []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                b_val = bathy.values[j, i]\n",
    "                if not np.isnan(b_val) and b_val > 0:\n",
    "                    coords.append((j, i))\n",
    "                    bathy_vals.append(b_val)\n",
    "\n",
    "    if not bathy_vals:\n",
    "        pixel_centers = []\n",
    "        for j in range(height):\n",
    "            for i in range(width):\n",
    "                x_c, y_c = transform * (i + 0.5, j + 0.5)\n",
    "                pixel_centers.append((j, i, Point(x_c, y_c)))\n",
    "\n",
    "        distances = []\n",
    "        for (j, i, pt) in pixel_centers:\n",
    "            dist = pt.distance(poly_proj)\n",
    "            b_val = bathy.values[j, i]\n",
    "            if not np.isnan(b_val) and b_val > 0:\n",
    "                distances.append((dist, j, i, b_val))\n",
    "\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        closest = distances[:3]\n",
    "        coords = [(j, i) for _, j, i, _ in closest]\n",
    "        bathy_vals = [b for _, _, _, b in closest]\n",
    "\n",
    "    layers_phys = [int(depth_sampling / b * 60) for b in bathy_vals]\n",
    "    layers_phys = [60 - l for l in layers_phys]\n",
    "    layers_index = [max(0, min(l - 1, 59)) for l in layers_phys]\n",
    "\n",
    "    temp_values = []\n",
    "    sal_values = []\n",
    "    for (j, i), l in zip(coords, layers_index):\n",
    "        t_val = temp.values[0, l, j, i]\n",
    "        s_val = sal.values[0, l, j, i]\n",
    "        if not np.isnan(t_val):\n",
    "            temp_values.append(t_val)\n",
    "        if not np.isnan(s_val):\n",
    "            sal_values.append(s_val)\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "    return temp_values, sal_values\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/SAL-TEMP_latlon/3H/\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse.geojson\")\n",
    "\n",
    "    min_temp = []\n",
    "    max_temp = []\n",
    "    mean_temp = []\n",
    "\n",
    "    min_sal = []\n",
    "    max_sal = []\n",
    "    mean_sal = []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction Temp & Sal sur 24h\"):\n",
    "        dt = row['datetime']\n",
    "        try:\n",
    "            files = get_netcdf_paths_for_period(dt, base_folder, hours=24)\n",
    "            all_temp_values = []\n",
    "            all_sal_values = []\n",
    "\n",
    "            for f in files:\n",
    "                t_vals, s_vals = get_temp_sal_for_poly(row['geometry'], row['depth_sampling'], f)\n",
    "                all_temp_values.extend(t_vals)\n",
    "                all_sal_values.extend(s_vals)\n",
    "\n",
    "            if all_temp_values:\n",
    "                min_temp.append(np.min(all_temp_values))\n",
    "                max_temp.append(np.max(all_temp_values))\n",
    "                mean_temp.append(np.mean(all_temp_values))\n",
    "            else:\n",
    "                min_temp.append(np.nan)\n",
    "                max_temp.append(np.nan)\n",
    "                mean_temp.append(np.nan)\n",
    "\n",
    "            if all_sal_values:\n",
    "                min_sal.append(np.min(all_sal_values))\n",
    "                max_sal.append(np.max(all_sal_values))\n",
    "                mean_sal.append(np.mean(all_sal_values))\n",
    "            else:\n",
    "                min_sal.append(np.nan)\n",
    "                max_sal.append(np.nan)\n",
    "                mean_sal.append(np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            min_temp.append(np.nan)\n",
    "            max_temp.append(np.nan)\n",
    "            mean_temp.append(np.nan)\n",
    "\n",
    "            min_sal.append(np.nan)\n",
    "            max_sal.append(np.nan)\n",
    "            mean_sal.append(np.nan)\n",
    "\n",
    "    gdf['temp_min_24h'] = min_temp\n",
    "    gdf['temp_max_24h'] = max_temp\n",
    "    gdf['temp_mean_24h'] = mean_temp\n",
    "\n",
    "    gdf['sal_min_24h'] = min_sal\n",
    "    gdf['sal_max_24h'] = max_sal\n",
    "    gdf['sal_mean_24h'] = mean_sal\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043af88",
   "metadata": {},
   "source": [
    "#### Extraction 7 jours en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "826fc119",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction 7 jours: 100%|██████████| 321/321 [1:57:10<00:00, 21.90s/it]\n"
     ]
    }
   ],
   "source": [
    "# 7 jours \n",
    "\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_period(dt, base_folder, days, stat_type):\n",
    "    \"\"\"Retourne la liste des fichiers journaliers pour les `days` jours avant dt (inclus).\"\"\"\n",
    "    start_dt = dt - timedelta(days=days)\n",
    "    files = []\n",
    "\n",
    "    for day in (start_dt + timedelta(n) for n in range((dt - start_dt).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Aucun fichier {stat_type} trouvé entre {start_dt} et {dt}\"\n",
    "        )\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "\n",
    "def get_temp_sal_for_poly(poly, depth_sampling, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    bathy = ds['H0']\n",
    "    temp = ds['TEMP']\n",
    "    sal = ds['SAL']\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(bathy.rio.crs).iloc[0]\n",
    "\n",
    "    transform = bathy.rio.transform()\n",
    "    height, width = bathy.shape\n",
    "\n",
    "    coords = []\n",
    "    bathy_vals = []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                b_val = bathy.values[j, i]\n",
    "                if not np.isnan(b_val) and b_val > 0:\n",
    "                    coords.append((j, i))\n",
    "                    bathy_vals.append(b_val)\n",
    "\n",
    "    if not bathy_vals:\n",
    "        pixel_centers = []\n",
    "        for j in range(height):\n",
    "            for i in range(width):\n",
    "                x_c, y_c = transform * (i + 0.5, j + 0.5)\n",
    "                pixel_centers.append((j, i, Point(x_c, y_c)))\n",
    "\n",
    "        distances = []\n",
    "        for (j, i, pt) in pixel_centers:\n",
    "            dist = pt.distance(poly_proj)\n",
    "            b_val = bathy.values[j, i]\n",
    "            if not np.isnan(b_val) and b_val > 0:\n",
    "                distances.append((dist, j, i, b_val))\n",
    "\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        closest = distances[:3]\n",
    "        coords = [(j, i) for _, j, i, _ in closest]\n",
    "        bathy_vals = [b for _, _, _, b in closest]\n",
    "\n",
    "    layers_phys = [int(depth_sampling / b * 60) for b in bathy_vals]\n",
    "    layers_phys = [60 - l for l in layers_phys]\n",
    "    layers_index = [max(0, min(l - 1, 59)) for l in layers_phys]\n",
    "\n",
    "    temp_values = []\n",
    "    sal_values = []\n",
    "    for (j, i), l in zip(coords, layers_index):\n",
    "        if temp.ndim == 4:  # Ancien format avec time\n",
    "            t_val = temp.values[0, l, j, i]\n",
    "            s_val = sal.values[0, l, j, i]\n",
    "        else:  # Nouveau format journalier sans time\n",
    "            t_val = temp.values[l, j, i]\n",
    "            s_val = sal.values[l, j, i]\n",
    "        if not np.isnan(t_val):\n",
    "            temp_values.append(t_val)\n",
    "        if not np.isnan(s_val):\n",
    "            sal_values.append(s_val)\n",
    "\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "    return temp_values, sal_values\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/SAL-TEMP_latlon/Daily/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse.geojson\")\n",
    "\n",
    "    temp_max7 = []\n",
    "    temp_min7 = []\n",
    "    temp_mean7 = []\n",
    "    sal_max7 = []\n",
    "    sal_min7 = []\n",
    "    sal_mean7 = []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction 7 jours\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        try:\n",
    "            # MAX du max\n",
    "            files_max = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"max\")\n",
    "            all_temp, all_sal = [], []\n",
    "            for f in files_max:\n",
    "                t_vals, s_vals = get_temp_sal_for_poly(row['geometry'], row['depth_sampling'], f)\n",
    "                all_temp.extend(t_vals)\n",
    "                all_sal.extend(s_vals)\n",
    "            temp_max7.append(np.nanmax(all_temp) if all_temp else np.nan)\n",
    "            sal_max7.append(np.nanmax(all_sal) if all_sal else np.nan)\n",
    "\n",
    "            # MIN du min\n",
    "            files_min = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"min\")\n",
    "            all_temp, all_sal = [], []\n",
    "            for f in files_min:\n",
    "                t_vals, s_vals = get_temp_sal_for_poly(row['geometry'], row['depth_sampling'], f)\n",
    "                all_temp.extend(t_vals)\n",
    "                all_sal.extend(s_vals)\n",
    "            temp_min7.append(np.nanmin(all_temp) if all_temp else np.nan)\n",
    "            sal_min7.append(np.nanmin(all_sal) if all_sal else np.nan)\n",
    "\n",
    "            # MOYENNE des mean\n",
    "            files_mean = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"mean\")\n",
    "            all_temp, all_sal = [], []\n",
    "            for f in files_mean:\n",
    "                t_vals, s_vals = get_temp_sal_for_poly(row['geometry'], row['depth_sampling'], f)\n",
    "                all_temp.extend(t_vals)\n",
    "                all_sal.extend(s_vals)\n",
    "            temp_mean7.append(np.nanmean(all_temp) if all_temp else np.nan)\n",
    "            sal_mean7.append(np.nanmean(all_sal) if all_sal else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            temp_max7.append(np.nan)\n",
    "            temp_min7.append(np.nan)\n",
    "            temp_mean7.append(np.nan)\n",
    "            sal_max7.append(np.nan)\n",
    "            sal_min7.append(np.nan)\n",
    "            sal_mean7.append(np.nan)\n",
    "\n",
    "    gdf['temp_max_7j'] = temp_max7\n",
    "    gdf['temp_min_7j'] = temp_min7\n",
    "    gdf['temp_mean_7j'] = temp_mean7\n",
    "    gdf['sal_max_7j'] = sal_max7\n",
    "    gdf['sal_min_7j'] = sal_min7\n",
    "    gdf['sal_mean_7j'] = sal_mean7\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac58a",
   "metadata": {},
   "source": [
    "#### Extraction un mois en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6455ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction sur 1 mois glissant: 100%|██████████| 321/321 [8:40:35<00:00, 97.31s/it]   \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_last_month(dt, base_folder, stat_type):\n",
    "    \"\"\"\n",
    "    Retourne la liste des fichiers journaliers pour un mois glissant\n",
    "    allant de (dt - 1 mois) à dt inclus.\n",
    "    \"\"\"\n",
    "    start_dt = dt - relativedelta(months=1)\n",
    "    end_dt = dt\n",
    "\n",
    "    files = []\n",
    "    for day in (start_dt + timedelta(n) for n in range((end_dt - start_dt).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Aucun fichier {stat_type} trouvé entre {start_dt} et {end_dt}\"\n",
    "        )\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_temp_sal_for_poly(poly, depth_sampling, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    bathy = ds['H0']\n",
    "    temp = ds['TEMP']\n",
    "    sal = ds['SAL']\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(bathy.rio.crs).iloc[0]\n",
    "\n",
    "    transform = bathy.rio.transform()\n",
    "    height, width = bathy.shape\n",
    "\n",
    "    coords = []\n",
    "    bathy_vals = []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                b_val = bathy.values[j, i]\n",
    "                if not np.isnan(b_val) and b_val > 0:\n",
    "                    coords.append((j, i))\n",
    "                    bathy_vals.append(b_val)\n",
    "\n",
    "    if not bathy_vals:\n",
    "        pixel_centers = []\n",
    "        for j in range(height):\n",
    "            for i in range(width):\n",
    "                x_c, y_c = transform * (i + 0.5, j + 0.5)\n",
    "                pixel_centers.append((j, i, Point(x_c, y_c)))\n",
    "\n",
    "        distances = []\n",
    "        for (j, i, pt) in pixel_centers:\n",
    "            dist = pt.distance(poly_proj)\n",
    "            b_val = bathy.values[j, i]\n",
    "            if not np.isnan(b_val) and b_val > 0:\n",
    "                distances.append((dist, j, i, b_val))\n",
    "\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        closest = distances[:3]\n",
    "        coords = [(j, i) for _, j, i, _ in closest]\n",
    "        bathy_vals = [b for _, _, _, b in closest]\n",
    "\n",
    "    layers_phys = [int(depth_sampling / b * 60) for b in bathy_vals]\n",
    "    layers_phys = [60 - l for l in layers_phys]\n",
    "    layers_index = [max(0, min(l - 1, 59)) for l in layers_phys]\n",
    "\n",
    "    temp_values = []\n",
    "    sal_values = []\n",
    "    for (j, i), l in zip(coords, layers_index):\n",
    "        if temp.ndim == 4:  # Ancien format avec time\n",
    "            t_val = temp.values[0, l, j, i]\n",
    "            s_val = sal.values[0, l, j, i]\n",
    "        else:  # Nouveau format journalier sans time\n",
    "            t_val = temp.values[l, j, i]\n",
    "            s_val = sal.values[l, j, i]\n",
    "        if not np.isnan(t_val):\n",
    "            temp_values.append(t_val)\n",
    "        if not np.isnan(s_val):\n",
    "            sal_values.append(s_val)\n",
    "\n",
    "    ds.close()\n",
    "    return temp_values, sal_values\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/SAL-TEMP_latlon/Daily/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse.geojson\")\n",
    "\n",
    "    temp_max, temp_min, temp_mean = [], [], []\n",
    "    sal_max, sal_min, sal_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction sur 1 mois glissant\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        try:\n",
    "            # MAX du max\n",
    "            files_max = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"max\")\n",
    "            all_temp, all_sal = [], []\n",
    "            for f in files_max:\n",
    "                t_vals, s_vals = get_temp_sal_for_poly(row['geometry'], row['depth_sampling'], f)\n",
    "                all_temp.extend(t_vals)\n",
    "                all_sal.extend(s_vals)\n",
    "            temp_max.append(np.nanmax(all_temp) if all_temp else np.nan)\n",
    "            sal_max.append(np.nanmax(all_sal) if all_sal else np.nan)\n",
    "\n",
    "            # MIN du min\n",
    "            files_min = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"min\")\n",
    "            all_temp, all_sal = [], []\n",
    "            for f in files_min:\n",
    "                t_vals, s_vals = get_temp_sal_for_poly(row['geometry'], row['depth_sampling'], f)\n",
    "                all_temp.extend(t_vals)\n",
    "                all_sal.extend(s_vals)\n",
    "            temp_min.append(np.nanmin(all_temp) if all_temp else np.nan)\n",
    "            sal_min.append(np.nanmin(all_sal) if all_sal else np.nan)\n",
    "\n",
    "            # MOYENNE des mean\n",
    "            files_mean = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"mean\")\n",
    "            all_temp, all_sal = [], []\n",
    "            for f in files_mean:\n",
    "                t_vals, s_vals = get_temp_sal_for_poly(row['geometry'], row['depth_sampling'], f)\n",
    "                all_temp.extend(t_vals)\n",
    "                all_sal.extend(s_vals)\n",
    "            temp_mean.append(np.nanmean(all_temp) if all_temp else np.nan)\n",
    "            sal_mean.append(np.nanmean(all_sal) if all_sal else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            temp_max.append(np.nan)\n",
    "            temp_min.append(np.nan)\n",
    "            temp_mean.append(np.nan)\n",
    "            sal_max.append(np.nan)\n",
    "            sal_min.append(np.nan)\n",
    "            sal_mean.append(np.nan)\n",
    "\n",
    "    gdf['temp_max_1m'] = temp_max\n",
    "    gdf['temp_min_1m'] = temp_min\n",
    "    gdf['temp_mean_1m'] = temp_mean\n",
    "    gdf['sal_max_1m'] = sal_max\n",
    "    gdf['sal_min_1m'] = sal_min\n",
    "    gdf['sal_mean_1m'] = sal_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc9ed4c",
   "metadata": {},
   "source": [
    "#### Extraction un an en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec952716",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction 1 an: 100%|██████████| 321/321 [8:13:01<00:00, 92.16s/it]   \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Fonctions utilitaires\n",
    "# -----------------------------\n",
    "\n",
    "def get_monthly_paths(dt_start, dt_end, base_folder, stat_type):\n",
    "    \"\"\"Retourne les fichiers mensuels (min/max/mean) entre dt_start et le mois précédent dt_end.\"\"\"\n",
    "    files = []\n",
    "    months = pd.date_range(start=dt_start, end=dt_end, freq='MS')  # Month Start\n",
    "    for month in months[:-1]:  # tous les mois sauf le dernier\n",
    "        year_folder = os.path.join(base_folder, str(month.year))\n",
    "        fname = f\"MARS3D_{month.strftime('%Y%m')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "    return files\n",
    "\n",
    "def get_daily_paths(dt_start, dt_end, base_folder, stat_type):\n",
    "    \"\"\"Retourne les fichiers journaliers (min/max/mean) entre dt_start et dt_end.\"\"\"\n",
    "    files = []\n",
    "    for day in (dt_start + timedelta(n) for n in range((dt_end - dt_start).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "    return files\n",
    "\n",
    "def get_temp_sal_for_poly(poly, depth_sampling, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    bathy = ds['H0']\n",
    "    temp = ds['TEMP']\n",
    "    sal = ds['SAL']\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(bathy.rio.crs).iloc[0]\n",
    "\n",
    "    transform = bathy.rio.transform()\n",
    "    height, width = bathy.shape\n",
    "\n",
    "    coords = []\n",
    "    bathy_vals = []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_min + (y_max - y_min))\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                b_val = bathy.values[j, i]\n",
    "                if not np.isnan(b_val) and b_val > 0:\n",
    "                    coords.append((j, i))\n",
    "                    bathy_vals.append(b_val)\n",
    "\n",
    "    if not bathy_vals:\n",
    "        # Si aucun pixel intersecte, prendre les 3 pixels les plus proches\n",
    "        pixel_centers = []\n",
    "        for j in range(height):\n",
    "            for i in range(width):\n",
    "                x_c, y_c = transform * (i + 0.5, j + 0.5)\n",
    "                pixel_centers.append((j, i, Point(x_c, y_c)))\n",
    "\n",
    "        distances = []\n",
    "        for (j, i, pt) in pixel_centers:\n",
    "            dist = pt.distance(poly_proj)\n",
    "            b_val = bathy.values[j, i]\n",
    "            if not np.isnan(b_val) and b_val > 0:\n",
    "                distances.append((dist, j, i, b_val))\n",
    "\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        closest = distances[:3]\n",
    "        coords = [(j, i) for _, j, i, _ in closest]\n",
    "        bathy_vals = [b for _, _, _, b in closest]\n",
    "\n",
    "    layers_phys = [int(depth_sampling / b * 60) for b in bathy_vals]\n",
    "    layers_phys = [60 - l for l in layers_phys]\n",
    "    layers_index = [max(0, min(l - 1, 59)) for l in layers_phys]\n",
    "\n",
    "    temp_values = []\n",
    "    sal_values = []\n",
    "    for (j, i), l in zip(coords, layers_index):\n",
    "        if temp.ndim == 4:  # Ancien format avec time\n",
    "            t_val = temp.values[0, l, j, i]\n",
    "            s_val = sal.values[0, l, j, i]\n",
    "        else:  # Nouveau format journalier sans time\n",
    "            t_val = temp.values[l, j, i]\n",
    "            s_val = sal.values[l, j, i]\n",
    "        if not np.isnan(t_val):\n",
    "            temp_values.append(t_val)\n",
    "        if not np.isnan(s_val):\n",
    "            sal_values.append(s_val)\n",
    "\n",
    "    ds.close()\n",
    "    return temp_values, sal_values\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    daily_base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/SAL-TEMP_latlon/Daily/Corse2\"\n",
    "    monthly_base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/SAL-TEMP_latlon/Monthly/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse.geojson\")\n",
    "\n",
    "    temp_max, temp_min, temp_mean = [], [], []\n",
    "    sal_max, sal_min, sal_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction 1 an\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        dt_start = dt - timedelta(days=365)\n",
    "        last_month_start = dt.replace(day=1)\n",
    "\n",
    "        try:\n",
    "            all_stats = {}\n",
    "            for stat in ['max', 'min', 'mean']:\n",
    "                # Fichiers mensuels sauf dernier mois\n",
    "                files_monthly = get_monthly_paths(dt_start, last_month_start, monthly_base_folder, stat)\n",
    "                # Fichiers journaliers du dernier mois\n",
    "                files_daily = get_daily_paths(last_month_start, dt, daily_base_folder, stat)\n",
    "                files = files_monthly + files_daily\n",
    "\n",
    "                all_temp, all_sal = [], []\n",
    "                for f in files:\n",
    "                    t_vals, s_vals = get_temp_sal_for_poly(row['geometry'], row['depth_sampling'], f)\n",
    "                    all_temp.extend(t_vals)\n",
    "                    all_sal.extend(s_vals)\n",
    "\n",
    "                if stat == 'max':\n",
    "                    temp_max.append(np.nanmax(all_temp) if all_temp else np.nan)\n",
    "                    sal_max.append(np.nanmax(all_sal) if all_sal else np.nan)\n",
    "                elif stat == 'min':\n",
    "                    temp_min.append(np.nanmin(all_temp) if all_temp else np.nan)\n",
    "                    sal_min.append(np.nanmin(all_sal) if all_sal else np.nan)\n",
    "                elif stat == 'mean':\n",
    "                    temp_mean.append(np.nanmean(all_temp) if all_temp else np.nan)\n",
    "                    sal_mean.append(np.nanmean(all_sal) if all_sal else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            temp_max.append(np.nan)\n",
    "            temp_min.append(np.nan)\n",
    "            temp_mean.append(np.nan)\n",
    "            sal_max.append(np.nan)\n",
    "            sal_min.append(np.nan)\n",
    "            sal_mean.append(np.nan)\n",
    "\n",
    "    gdf['temp_max_1y'] = temp_max\n",
    "    gdf['temp_min_1y'] = temp_min\n",
    "    gdf['temp_mean_1y'] = temp_mean\n",
    "    gdf['sal_max_1y'] = sal_max\n",
    "    gdf['sal_min_1y'] = sal_min\n",
    "    gdf['sal_mean_1y'] = sal_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cad5b3",
   "metadata": {},
   "source": [
    "### 2. Extraction des variables WINDSTRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99a956",
   "metadata": {},
   "source": [
    "#### Extraction 24H en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9146d193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_period(dt, base_folder, hours=24):\n",
    "    start_dt = dt - timedelta(hours=hours)\n",
    "    files = []\n",
    "\n",
    "    for year in range(start_dt.year, dt.year + 1):\n",
    "        year_folder = os.path.join(base_folder, str(year))\n",
    "        pattern = os.path.join(year_folder, \"MARC_F2-MARS3D-MENOR1200_????????T????Z.nc\")\n",
    "        candidates = glob.glob(pattern)\n",
    "\n",
    "        def extract_datetime_from_filename(f):\n",
    "            match = re.search(r\"_(\\d{8}T\\d{4})Z\\.nc$\", f)\n",
    "            if not match:\n",
    "                return None\n",
    "            return datetime.strptime(match.group(1), \"%Y%m%dT%H%M\")\n",
    "\n",
    "        for f in candidates:\n",
    "            f_dt = extract_datetime_from_filename(f)\n",
    "            if f_dt and start_dt <= f_dt <= dt:\n",
    "                files.append((f, f_dt))\n",
    "\n",
    "    files.sort(key=lambda x: x[1])\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"Aucun fichier trouvé entre {start_dt} et {dt}\")\n",
    "\n",
    "    return [f for f, _ in files]\n",
    "\n",
    "\n",
    "def get_windstress_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    windstress = ds['WINDSTRESS']\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(windstress.rio.crs).iloc[0]\n",
    "\n",
    "    transform = windstress.rio.transform()\n",
    "    height, width = windstress.shape[-2:]  # gère si data a dimension temps\n",
    "\n",
    "    coords = []\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                coords.append((j, i))\n",
    "\n",
    "    # si aucun pixel intersecte, on prend les 3 plus proches\n",
    "    if not coords:\n",
    "        pixel_centers = [\n",
    "            (j, i, Point(transform * (i + 0.5, j + 0.5)))\n",
    "            for j in range(height)\n",
    "            for i in range(width)\n",
    "        ]\n",
    "        distances = []\n",
    "        for (j, i, pt) in pixel_centers:\n",
    "            dist = pt.distance(poly_proj)\n",
    "            distances.append((dist, j, i))\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        coords = [(j, i) for _, j, i in distances[:3]]\n",
    "\n",
    "    wind_values = []\n",
    "    for (j, i) in coords:\n",
    "        # on suppose que la 1ère dimension est le temps\n",
    "        w_val = windstress.values[0, j, i] if windstress.ndim == 3 else windstress.values[j, i]\n",
    "        if not np.isnan(w_val):\n",
    "            wind_values.append(w_val)\n",
    "\n",
    "    ds.close()\n",
    "    return wind_values\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/3H/\"\n",
    "    gdf = gpd.read_file(\"test.geojson\")\n",
    "\n",
    "    min_wind, max_wind, mean_wind = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction WINDSTRESS sur 24h\"):\n",
    "        dt = row['datetime']\n",
    "        try:\n",
    "            files = get_netcdf_paths_for_period(dt, base_folder, hours=24)\n",
    "            all_wind_values = []\n",
    "\n",
    "            for f in files:\n",
    "                w_vals = get_windstress_for_poly(row['geometry'], f)\n",
    "                all_wind_values.extend(w_vals)\n",
    "\n",
    "            if all_wind_values:\n",
    "                min_wind.append(np.min(all_wind_values))\n",
    "                max_wind.append(np.max(all_wind_values))\n",
    "                mean_wind.append(np.mean(all_wind_values))\n",
    "            else:\n",
    "                min_wind.append(np.nan)\n",
    "                max_wind.append(np.nan)\n",
    "                mean_wind.append(np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            min_wind.append(np.nan)\n",
    "            max_wind.append(np.nan)\n",
    "            mean_wind.append(np.nan)\n",
    "\n",
    "    gdf['wind_min_24h'] = min_wind\n",
    "    gdf['wind_max_24h'] = max_wind\n",
    "    gdf['wind_mean_24h'] = mean_wind\n",
    "\n",
    "    gdf.to_file(\"test.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7f41e",
   "metadata": {},
   "source": [
    "#### Extraction 7 jours en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7bdf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_period(dt, base_folder, days, stat_type):\n",
    "    \"\"\"Retourne la liste des fichiers journaliers pour les `days` jours avant dt (inclus).\"\"\"\n",
    "    start_dt = dt - timedelta(days=days)\n",
    "    files = []\n",
    "\n",
    "    for day in (start_dt + timedelta(n) for n in range((dt - start_dt).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Aucun fichier {stat_type} trouvé entre {start_dt} et {dt}\"\n",
    "        )\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_windstress_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    windstress = ds['WINDSTRESS']  # variable 2D ou 3D (temps, y, x)\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(windstress.rio.crs).iloc[0]\n",
    "\n",
    "    transform = windstress.rio.transform()\n",
    "    height, width = windstress.shape[-2:]\n",
    "\n",
    "    coords = []\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                coords.append((j, i))\n",
    "\n",
    "    # Si aucun pixel intersecte, on prend les 3 plus proches\n",
    "    if not coords:\n",
    "        pixel_centers = [\n",
    "            (j, i, Point(transform * (i + 0.5, j + 0.5)))\n",
    "            for j in range(height)\n",
    "            for i in range(width)\n",
    "        ]\n",
    "        distances = [(pt.distance(poly_proj), j, i) for j, i, pt in pixel_centers]\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        coords = [(j, i) for _, j, i in distances[:3]]\n",
    "\n",
    "    wind_values = []\n",
    "    for (j, i) in coords:\n",
    "        if windstress.ndim == 3:  # format avec dimension temps\n",
    "            w_val = windstress.values[0, j, i]\n",
    "        else:  # format 2D\n",
    "            w_val = windstress.values[j, i]\n",
    "        if not np.isnan(w_val):\n",
    "            wind_values.append(w_val)\n",
    "\n",
    "    ds.close()\n",
    "    return wind_values\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse.geojson\")\n",
    "\n",
    "    wind_max7, wind_min7, wind_mean7 = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction WINDSTRESS sur 7 jours\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        try:\n",
    "            # MAX du max\n",
    "            files_max = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"max\")\n",
    "            all_wind = []\n",
    "            for f in files_max:\n",
    "                all_wind.extend(get_windstress_for_poly(row['geometry'], f))\n",
    "            wind_max7.append(np.nanmax(all_wind) if all_wind else np.nan)\n",
    "\n",
    "            # MIN du min\n",
    "            files_min = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"min\")\n",
    "            all_wind = []\n",
    "            for f in files_min:\n",
    "                all_wind.extend(get_windstress_for_poly(row['geometry'], f))\n",
    "            wind_min7.append(np.nanmin(all_wind) if all_wind else np.nan)\n",
    "\n",
    "            # MOYENNE des mean\n",
    "            files_mean = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"mean\")\n",
    "            all_wind = []\n",
    "            for f in files_mean:\n",
    "                all_wind.extend(get_windstress_for_poly(row['geometry'], f))\n",
    "            wind_mean7.append(np.nanmean(all_wind) if all_wind else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            wind_max7.append(np.nan)\n",
    "            wind_min7.append(np.nan)\n",
    "            wind_mean7.append(np.nan)\n",
    "\n",
    "    gdf['wind_max_7j'] = wind_max7\n",
    "    gdf['wind_min_7j'] = wind_min7\n",
    "    gdf['wind_mean_7j'] = wind_mean7\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97dd447",
   "metadata": {},
   "source": [
    "#### Extraction 1 mois en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641ac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def get_netcdf_paths_for_last_month(dt, base_folder, stat_type):\n",
    "    \"\"\"\n",
    "    Retourne la liste des fichiers journaliers pour le mois complet précédent dt.\n",
    "    Exemple : dt = 2022-08-02 => fichiers du 2022-07-01 au 2022-07-31\n",
    "    \"\"\"\n",
    "    start_dt = dt - relativedelta(months=1)\n",
    "    start_dt = start_dt.replace(day=1)  # premier jour du mois précédent\n",
    "    end_dt = dt.replace(day=1) - timedelta(days=1)  # dernier jour du mois précédent\n",
    "\n",
    "    files = []\n",
    "    for day in (start_dt + timedelta(n) for n in range((end_dt - start_dt).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Aucun fichier {stat_type} trouvé entre {start_dt} et {end_dt}\"\n",
    "        )\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_windstress_for_poly(poly, ncdf_path):\n",
    "    \"\"\"\n",
    "    Extrait les valeurs de WINDSTRESS pour les pixels intersectant le polygone.\n",
    "    Pas de filtre bathymétrique.\n",
    "    \"\"\"\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    wind = ds['WINDSTRESS']\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(wind.rio.crs).iloc[0]\n",
    "\n",
    "    transform = wind.rio.transform()\n",
    "    height, width = wind.shape[-2], wind.shape[-1]\n",
    "\n",
    "    coords = []\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_min)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                coords.append((j, i))\n",
    "\n",
    "    wind_values = []\n",
    "    for j, i in coords:\n",
    "        if wind.ndim == 4:  # format (time, depth, y, x)\n",
    "            w_val = wind.values[0, 0, j, i]\n",
    "        elif wind.ndim == 3:  # format (time, y, x) ou (depth, y, x)\n",
    "            w_val = wind.values[0, j, i]\n",
    "        else:  # format (y, x)\n",
    "            w_val = wind.values[j, i]\n",
    "        if not np.isnan(w_val):\n",
    "            wind_values.append(w_val)\n",
    "\n",
    "    ds.close()\n",
    "    return wind_values\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse.geojson\")\n",
    "\n",
    "    wind_max = []\n",
    "    wind_min = []\n",
    "    wind_mean = []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction mois précédent\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        try:\n",
    "            # MAX\n",
    "            files_max = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"max\")\n",
    "            all_wind = []\n",
    "            for f in files_max:\n",
    "                w_vals = get_windstress_for_poly(row['geometry'], f)\n",
    "                all_wind.extend(w_vals)\n",
    "            wind_max.append(np.nanmax(all_wind) if all_wind else np.nan)\n",
    "\n",
    "            # MIN\n",
    "            files_min = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"min\")\n",
    "            all_wind = []\n",
    "            for f in files_min:\n",
    "                w_vals = get_windstress_for_poly(row['geometry'], f)\n",
    "                all_wind.extend(w_vals)\n",
    "            wind_min.append(np.nanmin(all_wind) if all_wind else np.nan)\n",
    "\n",
    "            # MOYENNE\n",
    "            files_mean = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"mean\")\n",
    "            all_wind = []\n",
    "            for f in files_mean:\n",
    "                w_vals = get_windstress_for_poly(row['geometry'], f)\n",
    "                all_wind.extend(w_vals)\n",
    "            wind_mean.append(np.nanmean(all_wind) if all_wind else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            wind_max.append(np.nan)\n",
    "            wind_min.append(np.nan)\n",
    "            wind_mean.append(np.nan)\n",
    "\n",
    "    gdf['wind_max_1m'] = wind_max\n",
    "    gdf['wind_min_1m'] = wind_min\n",
    "    gdf['wind_mean_1m'] = wind_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a7edda",
   "metadata": {},
   "source": [
    "#### Extraction 1 an en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e2dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Fonctions utilitaires\n",
    "# -----------------------------\n",
    "\n",
    "def get_monthly_paths(dt_start, dt_end, base_folder, stat_type):\n",
    "    \"\"\"Retourne les fichiers mensuels (min/max/mean) entre dt_start et le mois précédent dt_end.\"\"\"\n",
    "    files = []\n",
    "    months = pd.date_range(start=dt_start, end=dt_end, freq='MS')  # Month Start\n",
    "    for month in months[:-1]:  # tous les mois sauf le dernier\n",
    "        year_folder = os.path.join(base_folder, str(month.year))\n",
    "        fname = f\"MARS3D_{month.strftime('%Y%m')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "    return files\n",
    "\n",
    "def get_daily_paths(dt_start, dt_end, base_folder, stat_type):\n",
    "    \"\"\"Retourne les fichiers journaliers (min/max/mean) entre dt_start et dt_end.\"\"\"\n",
    "    files = []\n",
    "    for day in (dt_start + timedelta(n) for n in range((dt_end - dt_start).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "    return files\n",
    "\n",
    "def get_windstress_for_poly(poly, ncdf_path):\n",
    "    \"\"\"Extrait WINDSTRESS pour un polygone depuis un fichier NetCDF.\"\"\"\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    wind = ds['WINDSTRESS']\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(wind.rio.crs).iloc[0]\n",
    "    transform = wind.rio.transform()\n",
    "    height, width = wind.shape[-2], wind.shape[-1]\n",
    "\n",
    "    coords = []\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_min + (y_max - y_min))\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                coords.append((j, i))\n",
    "\n",
    "    wind_values = []\n",
    "    for j, i in coords:\n",
    "        if wind.ndim == 4:\n",
    "            w_val = wind.values[0, 0, j, i]\n",
    "        elif wind.ndim == 3:\n",
    "            w_val = wind.values[0, j, i]\n",
    "        else:\n",
    "            w_val = wind.values[j, i]\n",
    "        if not np.isnan(w_val):\n",
    "            wind_values.append(w_val)\n",
    "\n",
    "    ds.close()\n",
    "    return wind_values\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    daily_base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Corse2\"\n",
    "    monthly_base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Monthly/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse.geojson\")\n",
    "\n",
    "    wind_max, wind_min, wind_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction WINDSTRESS 1 an\"):\n",
    "        dt = row['date']\n",
    "        dt_start = dt - timedelta(days=365)\n",
    "        last_month_start = dt.replace(day=1)\n",
    "\n",
    "        try:\n",
    "            all_stats = {}\n",
    "            for stat in ['max', 'min', 'mean']:\n",
    "                files_monthly = get_monthly_paths(dt_start, last_month_start, monthly_base_folder, stat)\n",
    "                files_daily = get_daily_paths(last_month_start, dt, daily_base_folder, stat)\n",
    "                files = files_monthly + files_daily\n",
    "\n",
    "                all_wind = []\n",
    "                for f in files:\n",
    "                    all_wind.extend(get_windstress_for_poly(row['geometry'], f))\n",
    "\n",
    "                if stat == 'max':\n",
    "                    wind_max.append(np.nanmax(all_wind) if all_wind else np.nan)\n",
    "                elif stat == 'min':\n",
    "                    wind_min.append(np.nanmin(all_wind) if all_wind else np.nan)\n",
    "                elif stat == 'mean':\n",
    "                    wind_mean.append(np.nanmean(all_wind) if all_wind else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            wind_max.append(np.nan)\n",
    "            wind_min.append(np.nan)\n",
    "            wind_mean.append(np.nan)\n",
    "\n",
    "    gdf['wind_max_1y'] = wind_max\n",
    "    gdf['wind_min_1y'] = wind_min\n",
    "    gdf['wind_mean_1y'] = wind_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse_windstress.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mars3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
