{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc94ebf5-6169-46a2-9da4-51f7ff4d297b",
   "metadata": {},
   "source": [
    "## Extraction des variables force du vent et courant sur la zone Corse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c876c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction WINDSTRESS & VELOCITY sur 24h: 100%|██████████| 77/77 [5:14:15<00:00, 244.88s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_period(dt, base_folder, hours=24):\n",
    "    start_dt = dt - timedelta(hours=hours)\n",
    "    files = []\n",
    "\n",
    "    for year in range(start_dt.year, dt.year + 1):\n",
    "        year_folder = os.path.join(base_folder, str(year))\n",
    "        pattern = os.path.join(year_folder, \"MARC_F2-MARS3D-MENOR1200_????????T????Z.nc\")\n",
    "        candidates = glob.glob(pattern)\n",
    "\n",
    "        def extract_datetime_from_filename(f):\n",
    "            match = re.search(r\"_(\\d{8}T\\d{4})Z\\.nc$\", f)\n",
    "            if not match:\n",
    "                return None\n",
    "            return datetime.strptime(match.group(1), \"%Y%m%dT%H%M\")\n",
    "\n",
    "        for f in candidates:\n",
    "            f_dt = extract_datetime_from_filename(f)\n",
    "            if f_dt and start_dt <= f_dt <= dt:\n",
    "                files.append((f, f_dt))\n",
    "\n",
    "    files.sort(key=lambda x: x[1])\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"Aucun fichier trouvé entre {start_dt} et {dt}\")\n",
    "\n",
    "    return [f for f, _ in files]\n",
    "\n",
    "\n",
    "def get_ws_vel_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    ws = ds['WINDSTRESS']  # (time, y, x)\n",
    "    vel = ds['VELOCITY']   # (time, depth, y, x)\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(ws.rio.crs).iloc[0]\n",
    "\n",
    "    transform = ws.rio.transform()\n",
    "    height, width = ws.shape[1:]  # (time, y, x)\n",
    "\n",
    "    ws_vals, vel_vals = [], []\n",
    "    pixel_centers_ws, pixel_centers_vel = [], []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "\n",
    "            ws_val = ws.values[0, j, i]\n",
    "            vel_val = vel.values[0, -1, j, i]  # dernière couche\n",
    "\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                if not np.isnan(ws_val):\n",
    "                    ws_vals.append(ws_val)\n",
    "                if not np.isnan(vel_val):\n",
    "                    vel_vals.append(vel_val)\n",
    "\n",
    "            # Stocker les centres pour fallback\n",
    "            x_c, y_c = transform * (i + 0.5, j + 0.5)\n",
    "            if not np.isnan(ws_val):\n",
    "                pixel_centers_ws.append((ws_val, Point(x_c, y_c)))\n",
    "            if not np.isnan(vel_val):\n",
    "                pixel_centers_vel.append((vel_val, Point(x_c, y_c)))\n",
    "\n",
    "    # --- Fallback si aucune intersection ---\n",
    "    if not ws_vals and pixel_centers_ws:\n",
    "        distances = [(val, pt.distance(poly_proj)) for val, pt in pixel_centers_ws]\n",
    "        ws_vals = [val for val, _ in sorted(distances, key=lambda x: x[1])[:3]]\n",
    "\n",
    "    if not vel_vals and pixel_centers_vel:\n",
    "        distances = [(val, pt.distance(poly_proj)) for val, pt in pixel_centers_vel]\n",
    "        vel_vals = [val for val, _ in sorted(distances, key=lambda x: x[1])[:3]]\n",
    "\n",
    "    ds.close()\n",
    "    return ws_vals, vel_vals\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/3H\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse_null.geojson\")\n",
    "\n",
    "    ws_min, ws_max, ws_mean = [], [], []\n",
    "    vel_min, vel_max, vel_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction WINDSTRESS & VELOCITY sur 24h\"):\n",
    "        dt = row['datetime']\n",
    "        try:\n",
    "            files = get_netcdf_paths_for_period(dt, base_folder, hours=24)\n",
    "            all_ws, all_vel = [], []\n",
    "\n",
    "            for f in files:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "\n",
    "            # WINDSTRESS\n",
    "            if all_ws:\n",
    "                ws_min.append(np.min(all_ws))\n",
    "                ws_max.append(np.max(all_ws))\n",
    "                ws_mean.append(np.mean(all_ws))\n",
    "            else:\n",
    "                ws_min.append(np.nan)\n",
    "                ws_max.append(np.nan)\n",
    "                ws_mean.append(np.nan)\n",
    "\n",
    "            # VELOCITY\n",
    "            if all_vel:\n",
    "                vel_min.append(np.min(all_vel))\n",
    "                vel_max.append(np.max(all_vel))\n",
    "                vel_mean.append(np.mean(all_vel))\n",
    "            else:\n",
    "                vel_min.append(np.nan)\n",
    "                vel_max.append(np.nan)\n",
    "                vel_mean.append(np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            ws_min.append(np.nan)\n",
    "            ws_max.append(np.nan)\n",
    "            ws_mean.append(np.nan)\n",
    "            vel_min.append(np.nan)\n",
    "            vel_max.append(np.nan)\n",
    "            vel_mean.append(np.nan)\n",
    "\n",
    "    gdf['wind_min_24h'] = ws_min\n",
    "    gdf['wind_max_24h'] = ws_max\n",
    "    gdf['wind_mean_24h'] = ws_mean\n",
    "    gdf['vel_min_24h'] = vel_min\n",
    "    gdf['vel_max_24h'] = vel_max\n",
    "    gdf['vel_mean_24h'] = vel_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse_null.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf5840",
   "metadata": {},
   "source": [
    "#### Extraction 7 jours en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c94636fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction 7 jours WS/VEL: 100%|██████████| 77/77 [1:00:18<00:00, 46.99s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "def get_netcdf_paths_for_period(dt, base_folder, days, stat_type):\n",
    "    \"\"\"Retourne la liste des fichiers journaliers pour les `days` jours avant dt (inclus).\"\"\"\n",
    "    start_dt = dt - timedelta(days=days)\n",
    "    files = []\n",
    "\n",
    "    for day in (start_dt + timedelta(n) for n in range((dt - start_dt).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Aucun fichier {stat_type} trouvé entre {start_dt} et {dt}\"\n",
    "        )\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_ws_vel_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    \n",
    "    # WINDSTRESS : time=0\n",
    "    ws = ds['WINDSTRESS'].isel(time=0)\n",
    "\n",
    "    # VELOCITY : dernière couche de profondeur + time=0\n",
    "    if 'time' in ds['VELOCITY'].dims and 'level' in ds['VELOCITY'].dims:\n",
    "        vel = ds['VELOCITY'].isel(time=0, level=-1)\n",
    "    else:\n",
    "        raise ValueError(\"VELOCITY n'a pas les dimensions attendues (time, level, y, x)\")\n",
    "\n",
    "    # attribution CRS si manquant\n",
    "    if ws.rio.crs is None:\n",
    "        ws = ws.rio.write_crs(\"EPSG:4326\")\n",
    "    if vel.rio.crs is None:\n",
    "        vel = vel.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj_ws = poly_gs.to_crs(ws.rio.crs).iloc[0]\n",
    "    poly_proj_vel = poly_gs.to_crs(vel.rio.crs).iloc[0]\n",
    "\n",
    "    # --- WINDSTRESS extraction ---\n",
    "    transform_ws = ws.rio.transform()\n",
    "    height, width = ws.shape\n",
    "    ws_values = []\n",
    "\n",
    "    pixel_centers_ws = []  # pour fallback si pas d'intersection\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform_ws * (i, j)\n",
    "            x_max, y_min = transform_ws * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            val = ws.values[j, i]\n",
    "            if not np.isnan(val):\n",
    "                if poly_proj_ws.intersects(pixel_poly):\n",
    "                    ws_values.append(val)\n",
    "                # stocker aussi le centroïde\n",
    "                x_c, y_c = transform_ws * (i + 0.5, j + 0.5)\n",
    "                pixel_centers_ws.append((val, Point(x_c, y_c)))\n",
    "\n",
    "    # Fallback si aucune intersection\n",
    "    if not ws_values and pixel_centers_ws:\n",
    "        distances = [(val, pt.distance(poly_proj_ws)) for val, pt in pixel_centers_ws]\n",
    "        distances_sorted = sorted(distances, key=lambda x: x[1])\n",
    "        ws_values = [val for val, _ in distances_sorted[:3]]\n",
    "\n",
    "    # --- VELOCITY extraction ---\n",
    "    transform_vel = vel.rio.transform()\n",
    "    height, width = vel.shape\n",
    "    vel_values = []\n",
    "\n",
    "    pixel_centers_vel = []  # pour fallback si pas d'intersection\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform_vel * (i, j)\n",
    "            x_max, y_min = transform_vel * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            val = vel.values[j, i]\n",
    "            if not np.isnan(val):\n",
    "                if poly_proj_vel.intersects(pixel_poly):\n",
    "                    vel_values.append(val)\n",
    "                # stocker aussi le centroïde\n",
    "                x_c, y_c = transform_vel * (i + 0.5, j + 0.5)\n",
    "                pixel_centers_vel.append((val, Point(x_c, y_c)))\n",
    "\n",
    "    # Fallback si aucune intersection\n",
    "    if not vel_values and pixel_centers_vel:\n",
    "        distances = [(val, pt.distance(poly_proj_vel)) for val, pt in pixel_centers_vel]\n",
    "        distances_sorted = sorted(distances, key=lambda x: x[1])\n",
    "        vel_values = [val for val, _ in distances_sorted[:3]]\n",
    "\n",
    "    ds.close()\n",
    "    return ws_values, vel_values\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse_null.geojson\")\n",
    "\n",
    "    ws_max7, ws_min7, ws_mean7 = [], [], []\n",
    "    vel_max7, vel_min7, vel_mean7 = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction 7 jours WS/VEL\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        try:\n",
    "            # MAX du max\n",
    "            files_max = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"max\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_max:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_max7.append(np.nanmax(all_ws) if all_ws else np.nan)\n",
    "            vel_max7.append(np.nanmax(all_vel) if all_vel else np.nan)\n",
    "\n",
    "            # MIN du min\n",
    "            files_min = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"min\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_min:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_min7.append(np.nanmin(all_ws) if all_ws else np.nan)\n",
    "            vel_min7.append(np.nanmin(all_vel) if all_vel else np.nan)\n",
    "\n",
    "            # MOYENNE des mean\n",
    "            files_mean = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"mean\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_mean:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_mean7.append(np.nanmean(all_ws) if all_ws else np.nan)\n",
    "            vel_mean7.append(np.nanmean(all_vel) if all_vel else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            ws_max7.append(np.nan)\n",
    "            ws_min7.append(np.nan)\n",
    "            ws_mean7.append(np.nan)\n",
    "            vel_max7.append(np.nan)\n",
    "            vel_min7.append(np.nan)\n",
    "            vel_mean7.append(np.nan)\n",
    "\n",
    "    gdf['wind_max_7j'] = ws_max7\n",
    "    gdf['wind_min_7j'] = ws_min7\n",
    "    gdf['wind_mean_7j'] = ws_mean7\n",
    "    gdf['vel_max_7j'] = vel_max7\n",
    "    gdf['vel_min_7j'] = vel_min7\n",
    "    gdf['vel_mean_7j'] = vel_mean7\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse_null.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e6110",
   "metadata": {},
   "source": [
    "#### Extraction 1 mois en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ecabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction sur 1 mois glissant:   0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction sur 1 mois glissant: 100%|██████████| 77/77 [3:21:04<00:00, 156.68s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import box, Point\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_last_month(dt, base_folder, stat_type):\n",
    "    \"\"\"\n",
    "    Retourne la liste des fichiers journaliers pour un mois glissant\n",
    "    allant de (dt - 1 mois) à dt inclus.\n",
    "    \"\"\"\n",
    "    start_dt = dt - relativedelta(months=1)\n",
    "    end_dt = dt\n",
    "\n",
    "    files = []\n",
    "    for day in (start_dt + timedelta(n) for n in range((end_dt - start_dt).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Aucun fichier {stat_type} trouvé entre {start_dt} et {end_dt}\"\n",
    "        )\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_ws_vel_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, \"crs\"):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    ws = ds[\"WINDSTRESS\"]  # (time, y, x)\n",
    "    vel = ds[\"VELOCITY\"]   # (time, depth, y, x)\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(ws.rio.crs).iloc[0]\n",
    "\n",
    "    transform = ws.rio.transform()\n",
    "    _, height, width = ws.shape  # time, y, x\n",
    "\n",
    "    ws_vals = []\n",
    "    vel_vals = []\n",
    "    pixel_centers_ws, pixel_centers_vel = [], []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "\n",
    "            w_val = ws.values[0, j, i]  # temps unique\n",
    "            v_val = vel.values[0, -1, j, i]  # dernière profondeur\n",
    "\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                if not np.isnan(w_val):\n",
    "                    ws_vals.append(w_val)\n",
    "                if not np.isnan(v_val):\n",
    "                    vel_vals.append(v_val)\n",
    "\n",
    "            # Stocker centres pour fallback\n",
    "            x_c, y_c = transform * (i + 0.5, j + 0.5)\n",
    "            if not np.isnan(w_val):\n",
    "                pixel_centers_ws.append((w_val, Point(x_c, y_c)))\n",
    "            if not np.isnan(v_val):\n",
    "                pixel_centers_vel.append((v_val, Point(x_c, y_c)))\n",
    "\n",
    "    # --- Fallback si aucune intersection ---\n",
    "    if not ws_vals and pixel_centers_ws:\n",
    "        distances = [(val, pt.distance(poly_proj)) for val, pt in pixel_centers_ws]\n",
    "        ws_vals = [val for val, _ in sorted(distances, key=lambda x: x[1])[:3]]\n",
    "\n",
    "    if not vel_vals and pixel_centers_vel:\n",
    "        distances = [(val, pt.distance(poly_proj)) for val, pt in pixel_centers_vel]\n",
    "        vel_vals = [val for val, _ in sorted(distances, key=lambda x: x[1])[:3]]\n",
    "\n",
    "    ds.close()\n",
    "    return ws_vals, vel_vals\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse_null.geojson\")\n",
    "\n",
    "    ws_max, ws_min, ws_mean = [], [], []\n",
    "    vel_max, vel_min, vel_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction sur 1 mois glissant\"):\n",
    "        dt = row[\"date\"]\n",
    "\n",
    "        try:\n",
    "            # MAX du max\n",
    "            files_max = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"max\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_max:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row[\"geometry\"], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_max.append(np.nanmax(all_ws) if all_ws else np.nan)\n",
    "            vel_max.append(np.nanmax(all_vel) if all_vel else np.nan)\n",
    "\n",
    "            # MIN du min\n",
    "            files_min = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"min\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_min:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row[\"geometry\"], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_min.append(np.nanmin(all_ws) if all_ws else np.nan)\n",
    "            vel_min.append(np.nanmin(all_vel) if all_vel else np.nan)\n",
    "\n",
    "            # MOYENNE des mean\n",
    "            files_mean = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"mean\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_mean:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row[\"geometry\"], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_mean.append(np.nanmean(all_ws) if all_ws else np.nan)\n",
    "            vel_mean.append(np.nanmean(all_vel) if all_vel else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            ws_max.append(np.nan)\n",
    "            ws_min.append(np.nan)\n",
    "            ws_mean.append(np.nan)\n",
    "            vel_max.append(np.nan)\n",
    "            vel_min.append(np.nan)\n",
    "            vel_mean.append(np.nan)\n",
    "\n",
    "    gdf[\"wind_max_1m\"] = ws_max\n",
    "    gdf[\"wind_min_1m\"] = ws_min\n",
    "    gdf[\"wind_mean_1m\"] = ws_mean\n",
    "    gdf[\"vel_max_1m\"] = vel_max\n",
    "    gdf[\"vel_min_1m\"] = vel_min\n",
    "    gdf[\"vel_mean_1m\"] = vel_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse_null.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d78bc3",
   "metadata": {},
   "source": [
    "#### Extraction 1 an en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0e7336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction 1 an: 100%|██████████| 77/77 [2:43:20<00:00, 127.28s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Fonctions utilitaires\n",
    "# -----------------------------\n",
    "\n",
    "def get_monthly_paths(dt_start, dt_end, base_folder, stat_type):\n",
    "    \"\"\"Retourne les fichiers mensuels (min/max/mean) entre dt_start et le mois précédent dt_end.\"\"\"\n",
    "    files = []\n",
    "    months = pd.date_range(start=dt_start, end=dt_end, freq='MS')  # Month Start\n",
    "    for month in months[:-1]:  # tous les mois sauf le dernier\n",
    "        year_folder = os.path.join(base_folder, str(month.year))\n",
    "        fname = f\"MARS3D_{month.strftime('%Y%m')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "    return files\n",
    "\n",
    "def get_daily_paths(dt_start, dt_end, base_folder, stat_type):\n",
    "    \"\"\"Retourne les fichiers journaliers (min/max/mean) entre dt_start et dt_end.\"\"\"\n",
    "    files = []\n",
    "    for day in (dt_start + timedelta(n) for n in range((dt_end - dt_start).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "    return files\n",
    "\n",
    "def get_ws_vel_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    ws = ds['WINDSTRESS']  # (time, y, x)\n",
    "    vel = ds['VELOCITY']   # (time, depth, y, x)\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(ws.rio.crs).iloc[0]\n",
    "\n",
    "    transform = ws.rio.transform()\n",
    "    height, width = ws.shape[1:]  # time, y, x\n",
    "\n",
    "    ws_vals, vel_vals = [], []\n",
    "    pixel_centers_ws, pixel_centers_vel = [], []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "\n",
    "            ws_val = ws.values[0, j, i]\n",
    "            vel_val = vel.values[0, -1, j, i]  # dernière couche\n",
    "\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                if not np.isnan(ws_val):\n",
    "                    ws_vals.append(ws_val)\n",
    "                if not np.isnan(vel_val):\n",
    "                    vel_vals.append(vel_val)\n",
    "\n",
    "            # Stocker les centres pour fallback\n",
    "            x_c, y_c = transform * (i + 0.5, j + 0.5)\n",
    "            if not np.isnan(ws_val):\n",
    "                pixel_centers_ws.append((ws_val, Point(x_c, y_c)))\n",
    "            if not np.isnan(vel_val):\n",
    "                pixel_centers_vel.append((vel_val, Point(x_c, y_c)))\n",
    "\n",
    "    # --- Fallback si aucune intersection ---\n",
    "    if not ws_vals and pixel_centers_ws:\n",
    "        distances = [(val, pt.distance(poly_proj)) for val, pt in pixel_centers_ws]\n",
    "        ws_vals = [val for val, _ in sorted(distances, key=lambda x: x[1])[:3]]\n",
    "\n",
    "    if not vel_vals and pixel_centers_vel:\n",
    "        distances = [(val, pt.distance(poly_proj)) for val, pt in pixel_centers_vel]\n",
    "        vel_vals = [val for val, _ in sorted(distances, key=lambda x: x[1])[:3]]\n",
    "\n",
    "    ds.close()\n",
    "    return ws_vals, vel_vals\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    daily_base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Corse2\"\n",
    "    monthly_base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Monthly/Corse2\"\n",
    "    gdf = gpd.read_file(\"adne_extract_corse_null.geojson\")\n",
    "\n",
    "    ws_max, ws_min, ws_mean = [], [], []\n",
    "    vel_max, vel_min, vel_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction 1 an\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        dt_start = dt - timedelta(days=365)\n",
    "        last_month_start = dt.replace(day=1)\n",
    "\n",
    "        try:\n",
    "            for stat in ['max', 'min', 'mean']:\n",
    "                # Fichiers mensuels sauf dernier mois\n",
    "                files_monthly = get_monthly_paths(dt_start, last_month_start, monthly_base_folder, stat)\n",
    "                # Fichiers journaliers du dernier mois\n",
    "                files_daily = get_daily_paths(last_month_start, dt, daily_base_folder, stat)\n",
    "                files = files_monthly + files_daily\n",
    "\n",
    "                all_ws, all_vel = [], []\n",
    "                for f in files:\n",
    "                    ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                    all_ws.extend(ws_vals)\n",
    "                    all_vel.extend(vel_vals)\n",
    "\n",
    "                if stat == 'max':\n",
    "                    ws_max.append(np.nanmax(all_ws) if all_ws else np.nan)\n",
    "                    vel_max.append(np.nanmax(all_vel) if all_vel else np.nan)\n",
    "                elif stat == 'min':\n",
    "                    ws_min.append(np.nanmin(all_ws) if all_ws else np.nan)\n",
    "                    vel_min.append(np.nanmin(all_vel) if all_vel else np.nan)\n",
    "                elif stat == 'mean':\n",
    "                    ws_mean.append(np.nanmean(all_ws) if all_ws else np.nan)\n",
    "                    vel_mean.append(np.nanmean(all_vel) if all_vel else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            ws_max.append(np.nan)\n",
    "            ws_min.append(np.nan)\n",
    "            ws_mean.append(np.nan)\n",
    "            vel_max.append(np.nan)\n",
    "            vel_min.append(np.nan)\n",
    "            vel_mean.append(np.nan)\n",
    "\n",
    "    gdf['ws_max_1y'] = ws_max\n",
    "    gdf['ws_min_1y'] = ws_min\n",
    "    gdf['ws_mean_1y'] = ws_mean\n",
    "    gdf['vel_max_1y'] = vel_max\n",
    "    gdf['vel_min_1y'] = vel_min\n",
    "    gdf['vel_mean_1y'] = vel_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_corse_null.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
