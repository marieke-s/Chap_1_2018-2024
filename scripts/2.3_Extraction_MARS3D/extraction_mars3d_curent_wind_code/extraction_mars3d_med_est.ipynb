{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6835578f",
   "metadata": {},
   "source": [
    "## Extraction des variables force du vent et courant sur la zone Med Est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3755aeec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction WINDSTRESS & VELOCITY sur 24h: 100%|██████████| 397/397 [9:16:42<00:00, 84.14s/it]   \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_period(dt, base_folder, hours=24):\n",
    "    start_dt = dt - timedelta(hours=hours)\n",
    "    files = []\n",
    "\n",
    "    for year in range(start_dt.year, dt.year + 1):\n",
    "        year_folder = os.path.join(base_folder, str(year))\n",
    "        pattern = os.path.join(year_folder, \"MARC_F2-MARS3D-MENOR1200_????????T????Z.nc\")\n",
    "        candidates = glob.glob(pattern)\n",
    "\n",
    "        def extract_datetime_from_filename(f):\n",
    "            match = re.search(r\"_(\\d{8}T\\d{4})Z\\.nc$\", f)\n",
    "            if not match:\n",
    "                return None\n",
    "            return datetime.strptime(match.group(1), \"%Y%m%dT%H%M\")\n",
    "\n",
    "        for f in candidates:\n",
    "            f_dt = extract_datetime_from_filename(f)\n",
    "            if f_dt and start_dt <= f_dt <= dt:\n",
    "                files.append((f, f_dt))\n",
    "\n",
    "    files.sort(key=lambda x: x[1])\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"Aucun fichier trouvé entre {start_dt} et {dt}\")\n",
    "\n",
    "    return [f for f, _ in files]\n",
    "\n",
    "\n",
    "def get_ws_vel_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    ws = ds['WINDSTRESS']\n",
    "    vel = ds['VELOCITY']\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(ws.rio.crs).iloc[0]\n",
    "\n",
    "    transform = ws.rio.transform()\n",
    "    height, width = ws.shape[-2], ws.shape[-1]\n",
    "\n",
    "    coords = []\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                coords.append((j, i))\n",
    "\n",
    "    if not coords:\n",
    "        pixel_centers = []\n",
    "        for j in range(height):\n",
    "            for i in range(width):\n",
    "                x_c, y_c = transform * (i + 0.5, j + 0.5)\n",
    "                pixel_centers.append((j, i, Point(x_c, y_c)))\n",
    "\n",
    "        distances = [(pt.distance(poly_proj), j, i) for j, i, pt in pixel_centers]\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        coords = [(j, i) for _, j, i in distances[:3]]\n",
    "\n",
    "    ws_values = [ws.values[0, j, i] for (j, i) in coords if not np.isnan(ws.values[0, j, i])]\n",
    "    vel_values = [vel.values[0, 59, j, i] for (j, i) in coords if not np.isnan(vel.values[0, 59, j, i])]\n",
    "\n",
    "    ds.close()\n",
    "    return ws_values, vel_values\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/3H\"\n",
    "    gdf = gpd.read_file(\"adne_extract_med_est.geojson\")\n",
    "\n",
    "    ws_min, ws_max, ws_mean = [], [], []\n",
    "    vel_min, vel_max, vel_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction WINDSTRESS & VELOCITY sur 24h\"):\n",
    "        dt = row['datetime']\n",
    "        try:\n",
    "            files = get_netcdf_paths_for_period(dt, base_folder, hours=24)\n",
    "            all_ws, all_vel = [], []\n",
    "\n",
    "            for f in files:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "\n",
    "            # WINDSTRESS\n",
    "            if all_ws:\n",
    "                ws_min.append(np.min(all_ws))\n",
    "                ws_max.append(np.max(all_ws))\n",
    "                ws_mean.append(np.mean(all_ws))\n",
    "            else:\n",
    "                ws_min.append(np.nan)\n",
    "                ws_max.append(np.nan)\n",
    "                ws_mean.append(np.nan)\n",
    "\n",
    "            # VELOCITY\n",
    "            if all_vel:\n",
    "                vel_min.append(np.min(all_vel))\n",
    "                vel_max.append(np.max(all_vel))\n",
    "                vel_mean.append(np.mean(all_vel))\n",
    "            else:\n",
    "                vel_min.append(np.nan)\n",
    "                vel_max.append(np.nan)\n",
    "                vel_mean.append(np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            ws_min.append(np.nan)\n",
    "            ws_max.append(np.nan)\n",
    "            ws_mean.append(np.nan)\n",
    "            vel_min.append(np.nan)\n",
    "            vel_max.append(np.nan)\n",
    "            vel_mean.append(np.nan)\n",
    "\n",
    "    gdf['wind_min_24h'] = ws_min\n",
    "    gdf['wind_max_24h'] = ws_max\n",
    "    gdf['wind_mean_24h'] = ws_mean\n",
    "    gdf['vel_min_24h'] = vel_min\n",
    "    gdf['vel_max_24h'] = vel_max\n",
    "    gdf['vel_mean_24h'] = vel_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_med_est.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf5840",
   "metadata": {},
   "source": [
    "#### Extraction 7 jours en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c94636fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction 7 jours WS/VEL: 100%|██████████| 397/397 [5:21:45<00:00, 48.63s/it]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "def get_netcdf_paths_for_period(dt, base_folder, days, stat_type):\n",
    "    \"\"\"Retourne la liste des fichiers journaliers pour les `days` jours avant dt (inclus).\"\"\"\n",
    "    start_dt = dt - timedelta(days=days)\n",
    "    files = []\n",
    "\n",
    "    for day in (start_dt + timedelta(n) for n in range((dt - start_dt).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Aucun fichier {stat_type} trouvé entre {start_dt} et {dt}\"\n",
    "        )\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_ws_vel_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    \n",
    "    # WINDSTRESS : time=0\n",
    "    ws = ds['WINDSTRESS'].isel(time=0)\n",
    "\n",
    "    # VELOCITY : dernière couche de profondeur + time=0\n",
    "    if 'time' in ds['VELOCITY'].dims and 'level' in ds['VELOCITY'].dims:\n",
    "        vel = ds['VELOCITY'].isel(time=0, level=-1)\n",
    "    else:\n",
    "        raise ValueError(\"VELOCITY n'a pas les dimensions attendues (time, level, y, x)\")\n",
    "\n",
    "    # attribution CRS si manquant\n",
    "    if ws.rio.crs is None:\n",
    "        ws = ws.rio.write_crs(\"EPSG:4326\")\n",
    "    if vel.rio.crs is None:\n",
    "        vel = vel.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj_ws = poly_gs.to_crs(ws.rio.crs).iloc[0]\n",
    "    poly_proj_vel = poly_gs.to_crs(vel.rio.crs).iloc[0]\n",
    "\n",
    "    # WINDSTRESS extraction\n",
    "    transform_ws = ws.rio.transform()\n",
    "    height, width = ws.shape\n",
    "    ws_values = []\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform_ws * (i, j)\n",
    "            x_max, y_min = transform_ws * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            val = ws.values[j, i]\n",
    "            if not np.isnan(val) and poly_proj_ws.intersects(pixel_poly):\n",
    "                ws_values.append(val)\n",
    "\n",
    "    # VELOCITY extraction\n",
    "    transform_vel = vel.rio.transform()\n",
    "    height, width = vel.shape\n",
    "    vel_values = []\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform_vel * (i, j)\n",
    "            x_max, y_min = transform_vel * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            val = vel.values[j, i]\n",
    "            if not np.isnan(val) and poly_proj_vel.intersects(pixel_poly):\n",
    "                vel_values.append(val)\n",
    "\n",
    "    ds.close()\n",
    "    return ws_values, vel_values\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Med-Est\"\n",
    "    gdf = gpd.read_file(\"adne_extract_med_est.geojson\")\n",
    "\n",
    "    ws_max7, ws_min7, ws_mean7 = [], [], []\n",
    "    vel_max7, vel_min7, vel_mean7 = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction 7 jours WS/VEL\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        try:\n",
    "            # MAX du max\n",
    "            files_max = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"max\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_max:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_max7.append(np.nanmax(all_ws) if all_ws else np.nan)\n",
    "            vel_max7.append(np.nanmax(all_vel) if all_vel else np.nan)\n",
    "\n",
    "            # MIN du min\n",
    "            files_min = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"min\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_min:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_min7.append(np.nanmin(all_ws) if all_ws else np.nan)\n",
    "            vel_min7.append(np.nanmin(all_vel) if all_vel else np.nan)\n",
    "\n",
    "            # MOYENNE des mean\n",
    "            files_mean = get_netcdf_paths_for_period(dt, base_folder, days=7, stat_type=\"mean\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_mean:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_mean7.append(np.nanmean(all_ws) if all_ws else np.nan)\n",
    "            vel_mean7.append(np.nanmean(all_vel) if all_vel else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            ws_max7.append(np.nan)\n",
    "            ws_min7.append(np.nan)\n",
    "            ws_mean7.append(np.nan)\n",
    "            vel_max7.append(np.nan)\n",
    "            vel_min7.append(np.nan)\n",
    "            vel_mean7.append(np.nan)\n",
    "\n",
    "    gdf['wind_max_7j'] = ws_max7\n",
    "    gdf['wind_min_7j'] = ws_min7\n",
    "    gdf['wind_mean_7j'] = ws_mean7\n",
    "    gdf['vel_max_7j'] = vel_max7\n",
    "    gdf['vel_min_7j'] = vel_min7\n",
    "    gdf['vel_mean_7j'] = vel_mean7\n",
    "\n",
    "    gdf.to_file(\"adne_extract_med_est.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e6110",
   "metadata": {},
   "source": [
    "#### Extraction 1 mois en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ecabb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction sur 1 mois glissant: 100%|██████████| 397/397 [8:41:44<00:00, 78.85s/it]  \n"
     ]
    }
   ],
   "source": [
    "# 1 mois \n",
    "\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "\n",
    "def get_netcdf_paths_for_last_month(dt, base_folder, stat_type):\n",
    "    \"\"\"\n",
    "    Retourne la liste des fichiers journaliers pour un mois glissant\n",
    "    allant de (dt - 1 mois) à dt inclus.\n",
    "    \"\"\"\n",
    "    start_dt = dt - relativedelta(months=1)\n",
    "    end_dt = dt\n",
    "\n",
    "    files = []\n",
    "    for day in (start_dt + timedelta(n) for n in range((end_dt - start_dt).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(\n",
    "            f\"Aucun fichier {stat_type} trouvé entre {start_dt} et {end_dt}\"\n",
    "        )\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_ws_vel_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, \"crs\"):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    ws = ds[\"WINDSTRESS\"]  # (time, y, x)\n",
    "    vel = ds[\"VELOCITY\"]   # (time, depth, y, x)\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(ws.rio.crs).iloc[0]\n",
    "\n",
    "    transform = ws.rio.transform()\n",
    "    _, height, width = ws.shape  # time, y, x\n",
    "\n",
    "    ws_vals = []\n",
    "    vel_vals = []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                w_val = ws.values[0, j, i]  # 1 seule couche temps\n",
    "                v_val = vel.values[0, -1, j, i]  # couche 60 (dernière profondeur)\n",
    "                if not np.isnan(w_val):\n",
    "                    ws_vals.append(w_val)\n",
    "                if not np.isnan(v_val):\n",
    "                    vel_vals.append(v_val)\n",
    "\n",
    "    ds.close()\n",
    "    return ws_vals, vel_vals\n",
    "\n",
    "\n",
    "def main():\n",
    "    base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Med-Est\"\n",
    "    gdf = gpd.read_file(\"adne_extract_med_est.geojson\")\n",
    "\n",
    "    ws_max, ws_min, ws_mean = [], [], []\n",
    "    vel_max, vel_min, vel_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction sur 1 mois glissant\"):\n",
    "        dt = row[\"date\"]\n",
    "\n",
    "        try:\n",
    "            # MAX du max\n",
    "            files_max = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"max\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_max:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row[\"geometry\"], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_max.append(np.nanmax(all_ws) if all_ws else np.nan)\n",
    "            vel_max.append(np.nanmax(all_vel) if all_vel else np.nan)\n",
    "\n",
    "            # MIN du min\n",
    "            files_min = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"min\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_min:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row[\"geometry\"], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_min.append(np.nanmin(all_ws) if all_ws else np.nan)\n",
    "            vel_min.append(np.nanmin(all_vel) if all_vel else np.nan)\n",
    "\n",
    "            # MOYENNE des mean\n",
    "            files_mean = get_netcdf_paths_for_last_month(dt, base_folder, stat_type=\"mean\")\n",
    "            all_ws, all_vel = [], []\n",
    "            for f in files_mean:\n",
    "                ws_vals, vel_vals = get_ws_vel_for_poly(row[\"geometry\"], f)\n",
    "                all_ws.extend(ws_vals)\n",
    "                all_vel.extend(vel_vals)\n",
    "            ws_mean.append(np.nanmean(all_ws) if all_ws else np.nan)\n",
    "            vel_mean.append(np.nanmean(all_vel) if all_vel else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            ws_max.append(np.nan)\n",
    "            ws_min.append(np.nan)\n",
    "            ws_mean.append(np.nan)\n",
    "            vel_max.append(np.nan)\n",
    "            vel_min.append(np.nan)\n",
    "            vel_mean.append(np.nan)\n",
    "\n",
    "    gdf[\"wind_max_1m\"] = ws_max\n",
    "    gdf[\"wind_min_1m\"] = ws_min\n",
    "    gdf[\"wind_mean_1m\"] = ws_mean\n",
    "    gdf[\"vel_max_1m\"] = vel_max\n",
    "    gdf[\"vel_min_1m\"] = vel_min\n",
    "    gdf[\"vel_mean_1m\"] = vel_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_med_est.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d78bc3",
   "metadata": {},
   "source": [
    "#### Extraction 1 an en amont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0e7336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction 1 an: 100%|██████████| 397/397 [8:39:12<00:00, 78.47s/it]   \n"
     ]
    }
   ],
   "source": [
    "# 1 an \n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, box\n",
    "import os\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "\n",
    "# -----------------------------\n",
    "# Fonctions utilitaires\n",
    "# -----------------------------\n",
    "\n",
    "def get_monthly_paths(dt_start, dt_end, base_folder, stat_type):\n",
    "    \"\"\"Retourne les fichiers mensuels (min/max/mean) entre dt_start et le mois précédent dt_end.\"\"\"\n",
    "    files = []\n",
    "    months = pd.date_range(start=dt_start, end=dt_end, freq='MS')  # Month Start\n",
    "    for month in months[:-1]:  # tous les mois sauf le dernier\n",
    "        year_folder = os.path.join(base_folder, str(month.year))\n",
    "        fname = f\"MARS3D_{month.strftime('%Y%m')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "    return files\n",
    "\n",
    "def get_daily_paths(dt_start, dt_end, base_folder, stat_type):\n",
    "    \"\"\"Retourne les fichiers journaliers (min/max/mean) entre dt_start et dt_end.\"\"\"\n",
    "    files = []\n",
    "    for day in (dt_start + timedelta(n) for n in range((dt_end - dt_start).days + 1)):\n",
    "        year_folder = os.path.join(base_folder, str(day.year))\n",
    "        fname = f\"MARS3D_{day.strftime('%Y%m%d')}_{stat_type}.nc\"\n",
    "        fpath = os.path.join(year_folder, fname)\n",
    "        if os.path.exists(fpath):\n",
    "            files.append(fpath)\n",
    "    return files\n",
    "\n",
    "def get_ws_vel_for_poly(poly, ncdf_path):\n",
    "    ds = xr.open_dataset(ncdf_path, engine=\"netcdf4\")\n",
    "    if not hasattr(ds, 'crs'):\n",
    "        ds = ds.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    ws = ds['WINDSTRESS']  # (time, y, x)\n",
    "    vel = ds['VELOCITY']   # (time, depth, y, x)\n",
    "\n",
    "    poly_gs = gpd.GeoSeries([poly], crs=\"EPSG:4326\")\n",
    "    poly_proj = poly_gs.to_crs(ws.rio.crs).iloc[0]\n",
    "\n",
    "    transform = ws.rio.transform()\n",
    "    height, width = ws.shape[1:]  # time, y, x\n",
    "\n",
    "    ws_vals = []\n",
    "    vel_vals = []\n",
    "\n",
    "    for j in range(height):\n",
    "        for i in range(width):\n",
    "            x_min, y_max = transform * (i, j)\n",
    "            x_max, y_min = transform * (i + 1, j + 1)\n",
    "            pixel_poly = box(x_min, y_min, x_max, y_max)\n",
    "            if poly_proj.intersects(pixel_poly):\n",
    "                ws_val = ws.values[0, j, i]\n",
    "                vel_val = vel.values[0, -1, j, i]  # dernière couche\n",
    "                if not np.isnan(ws_val):\n",
    "                    ws_vals.append(ws_val)\n",
    "                if not np.isnan(vel_val):\n",
    "                    vel_vals.append(vel_val)\n",
    "\n",
    "    ds.close()\n",
    "    return ws_vals, vel_vals\n",
    "\n",
    "# -----------------------------\n",
    "# Main\n",
    "# -----------------------------\n",
    "\n",
    "def main():\n",
    "    daily_base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Daily/Med-Est\"\n",
    "    monthly_base_folder = \"/home/paulinev/Bureau/Marbec_data/BiodivMed/MARS3D/Med_MENOR/Aggregated/CUR-WIND_latlon/Monthly/Med-Est\"\n",
    "    gdf = gpd.read_file(\"adne_extract_med_est.geojson\")\n",
    "\n",
    "    ws_max, ws_min, ws_mean = [], [], []\n",
    "    vel_max, vel_min, vel_mean = [], [], []\n",
    "\n",
    "    for idx, row in tqdm(gdf.iterrows(), total=len(gdf), desc=\"Extraction 1 an\"):\n",
    "        dt = row['date']\n",
    "\n",
    "        dt_start = dt - timedelta(days=365)\n",
    "        last_month_start = dt.replace(day=1)\n",
    "\n",
    "        try:\n",
    "            for stat in ['max', 'min', 'mean']:\n",
    "                # Fichiers mensuels sauf dernier mois\n",
    "                files_monthly = get_monthly_paths(dt_start, last_month_start, monthly_base_folder, stat)\n",
    "                # Fichiers journaliers du dernier mois\n",
    "                files_daily = get_daily_paths(last_month_start, dt, daily_base_folder, stat)\n",
    "                files = files_monthly + files_daily\n",
    "\n",
    "                all_ws, all_vel = [], []\n",
    "                for f in files:\n",
    "                    ws_vals, vel_vals = get_ws_vel_for_poly(row['geometry'], f)\n",
    "                    all_ws.extend(ws_vals)\n",
    "                    all_vel.extend(vel_vals)\n",
    "\n",
    "                if stat == 'max':\n",
    "                    ws_max.append(np.nanmax(all_ws) if all_ws else np.nan)\n",
    "                    vel_max.append(np.nanmax(all_vel) if all_vel else np.nan)\n",
    "                elif stat == 'min':\n",
    "                    ws_min.append(np.nanmin(all_ws) if all_ws else np.nan)\n",
    "                    vel_min.append(np.nanmin(all_vel) if all_vel else np.nan)\n",
    "                elif stat == 'mean':\n",
    "                    ws_mean.append(np.nanmean(all_ws) if all_ws else np.nan)\n",
    "                    vel_mean.append(np.nanmean(all_vel) if all_vel else np.nan)\n",
    "\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Fichier manquant pour {dt}: {e}\")\n",
    "            ws_max.append(np.nan)\n",
    "            ws_min.append(np.nan)\n",
    "            ws_mean.append(np.nan)\n",
    "            vel_max.append(np.nan)\n",
    "            vel_min.append(np.nan)\n",
    "            vel_mean.append(np.nan)\n",
    "\n",
    "    gdf['ws_max_1y'] = ws_max\n",
    "    gdf['ws_min_1y'] = ws_min\n",
    "    gdf['ws_mean_1y'] = ws_mean\n",
    "    gdf['vel_max_1y'] = vel_max\n",
    "    gdf['vel_min_1y'] = vel_min\n",
    "    gdf['vel_mean_1y'] = vel_mean\n",
    "\n",
    "    gdf.to_file(\"adne_extract_med_est.geojson\", driver=\"GeoJSON\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
