


import calendar
import copernicusmarine
import dask
from datetime import datetime, timedelta
import exactextract as ee
from exactextract import exact_extract
import gc
import geopandas as gpd
import math
import matplotlib.pyplot as plt
import numpy as np
import os
import pandas as pd
from datetime import datetime, timedelta
import rasterio
from rasterio.mask import mask
from rasterio.features import geometry_mask
import rioxarray as rxr
from shapely.geometry import mapping, shape
from shapely.geometry import mapping, Point
from scipy.spatial import cKDTree
import time 
from tqdm import tqdm
import xarray as xr



os.chdir("/media/marieke/Shared/Chap-1/Model/Scripts/Chap_1_2018-2024")








# Set parameters
data_request = {
   "dataset_id" : "cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D",
   "longitude" : [3, 9.65], 
   "latitude" : [41.2, 44],
   "time" : ["2013-01-01", "2025-01-01"],
   "variables" : ["CHL"]
}

# Load xarray dataset
chl = copernicusmarine.open_dataset(
    dataset_id = data_request["dataset_id"],
    minimum_longitude = data_request["longitude"][0],
    maximum_longitude = data_request["longitude"][1],
    minimum_latitude = data_request["latitude"][0],
    maximum_latitude = data_request["latitude"][1],
    start_datetime = data_request["time"][0],
    end_datetime = data_request["time"][1],
    variables = data_request["variables"]
)

# Export to NCDF 
chl.to_netcdf("./data/raw_data/predictors/Chl/cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D_20130101-20250101.nc")












# Set parameters
data_request = {
   "dataset_id" : "med-ogs-bio-rean-d",
   "longitude" : [3, 9.65], 
   "latitude" : [41.2, 44],
   "time" : ["2013-01-01", "2025-01-01"],
   "variables" : ["02"]
}

# Load xarray dataset
ox = copernicusmarine.open_dataset(
    dataset_id = data_request["dataset_id"],
    minimum_longitude = data_request["longitude"][0],
    maximum_longitude = data_request["longitude"][1],
    minimum_latitude = data_request["latitude"][0],
    maximum_latitude = data_request["latitude"][1],
    start_datetime = data_request["time"][0],
    end_datetime = data_request["time"][1],
    variables = data_request["variables"]
)

# Export to NCDF 
ph.to_netcdf("./data/raw_data/predictors/oxygen/med-ogs-bio-rean-d _20130101-20250101.nc")






# Set parameters
data_request = {
   "dataset_id" : "cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D",
   "longitude" : [3, 9.65], 
   "latitude" : [41.2, 44],
   "time" : ["2013-01-01", "2025-01-01"],
   "variables" : ["CHL"]
}

# Load xarray dataset
chl = copernicusmarine.open_dataset(
    dataset_id = data_request["dataset_id"],
    minimum_longitude = data_request["longitude"][0],
    maximum_longitude = data_request["longitude"][1],
    minimum_latitude = data_request["latitude"][0],
    maximum_latitude = data_request["latitude"][1],
    start_datetime = data_request["time"][0],
    end_datetime = data_request["time"][1],
    variables = data_request["variables"]
)

# Export to NCDF 
chl.to_netcdf("./data/raw_data/predictors/Chl/cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D_20130101-20250101.nc")









# Set parameters
data_request = {
   "dataset_id" : "SST_MED_SST_L4_NRT_OBSERVATIONS_010_004_c_V2",
   "longitude" : [3, 9.65], 
   "latitude" : [41.2, 44],
   "time" : ["2013-01-01", "2025-01-01"],
   "variables" : ["analysed_sst"]
}

# Load xarray dataset
sst = copernicusmarine.open_dataset(
    dataset_id = data_request["dataset_id"],
    minimum_longitude = data_request["longitude"][0],
    maximum_longitude = data_request["longitude"][1],
    minimum_latitude = data_request["latitude"][0],
    maximum_latitude = data_request["latitude"][1],
    start_datetime = data_request["time"][0],
    end_datetime = data_request["time"][1],
    variables = data_request["variables"]
)

# Export to NCDF 
sst.to_netcdf("./data/raw_data/predictors/SST/SST_MED_SST_L4_NRT_OBSERVATIONS_010_004_c_V2_SST_20130101-20250101.nc")









# Set parameters
data_request = {
   "dataset_id" : "SST_MED_SST_L4_NRT_OBSERVATIONS_010_004_c_V2",
   "longitude" : [3, 9.65], 
   "latitude" : [41.2, 44],
   "time" : ["2013-01-01", "2025-01-01"],
   "variables" : ["analysed_sst"]
}

# Load xarray dataset
sst = copernicusmarine.open_dataset(
    dataset_id = data_request["dataset_id"],
    minimum_longitude = data_request["longitude"][0],
    maximum_longitude = data_request["longitude"][1],
    minimum_latitude = data_request["latitude"][0],
    maximum_latitude = data_request["latitude"][1],
    start_datetime = data_request["time"][0],
    end_datetime = data_request["time"][1],
    variables = data_request["variables"]
)

# Export to NCDF 
sst.to_netcdf("./data/raw_data/predictors/SST/SST_MED_SST_L4_NRT_OBSERVATIONS_010_004_c_V2_SST_20130101-20250101.nc")









# Pipeline with exactextract

def get_dates(date, time_step):
    """
    Calculate the range of dates for a given time step relative to the provided date.
    """
    from datetime import datetime, timedelta

    if isinstance(date, str):
        date = datetime.strptime(date, "%Y-%m-%d")

    end_date = date - timedelta(days=1)

    time_deltas = {
        'day': 1,
        'week': 7,
        'month': 30,
        'year': 365,
        '5years': 5 * 365 + 1,
    }

    if time_step not in time_deltas:
        raise ValueError("Unsupported time step. Choose from 'day', 'week', 'month', 'year', or '5years'.")

    start_date = date - timedelta(days=time_deltas[time_step])
    return start_date, end_date






def compute_stats(data_array, shape_geometry):
    """
    Extract values and compute weighted mean - automatically with exactextract- , min and max.
    """
    
    try:
        feature = {"type": "Feature", "geometry": mapping(shape_geometry), "properties": {}}
        res = exact_extract(data_array, [feature], ["mean", "min", "max"])


        if not res or len(res) == 0:
            return None, None, None

        props = res[0]["properties"]

        # Multi-band keys: band_1_mean, band_2_mean, etc.
        mean_vals = [v for k, v in props.items() if k.endswith("_mean")]
        min_vals  = [v for k, v in props.items() if k.endswith("_min")]
        max_vals  = [v for k, v in props.items() if k.endswith("_max")]

         # Single-band keys: mean, min, max
        if not mean_vals:
            if "mean" in props:
                mean_vals = [props["mean"]]
        if not min_vals:
            if "min" in props:
                min_vals = [props["min"]]
        if not max_vals:
            if "max" in props:
                max_vals = [props["max"]]
   

        if not mean_vals or not min_vals or not max_vals:
            return None, None, None

        mean_val = float(np.nanmean(mean_vals))
        min_val  = float(np.nanmin(min_vals))
        max_val  = float(np.nanmax(max_vals))

        return mean_val, min_val, max_val

    except Exception as e:
        print(f"compute_stats ERROR: {e}")
        return None, None, None







def open_nc(shape_geometry, date, netcdf_path, variable="CHL"):
    """
    Compute NCDF statistics for a given geometry and date using a netCDF file.
    """
    results = {}

    try:
        if isinstance(date, str):
            date = datetime.strptime(date, "%Y-%m-%d")

        ds = xr.open_dataset(netcdf_path)
        ds = ds.rio.write_crs("EPSG:4326", inplace=True)


        target_date = date - timedelta(days=1)
        time_steps = ["day", "week", "month", "year", "5years"]
        date_ranges = {label: get_dates(date, label) for label in time_steps}


        for label, (start_date, end_date) in date_ranges.items():
            ds_time_range = ds.sel(time=slice(start_date, end_date))

            if ds_time_range.time.size == 0:
                results[label] = (None, None, None, 0)
                continue

            chl_data = ds_time_range[variable]
            valid_data = chl_data.dropna(dim="time", how="all")


            if valid_data.size > 0:                 
                mean_val, min_val, max_val = compute_stats(valid_data, shape_geometry)                
                results[label] = (mean_val, min_val, max_val)
            else:
                print("valid_data.size == 0")
                results[label] = (None, None, None)

        return results

    except Exception as e:
        print(f"Error processing shape with target date: {date}: {e}")
        return {}







def process_geojson(geojson_path, netcdf_path, output_path, variable="CHL"):
    """
    Process the GeoJSON file and compute statistics for each shape using a netCDF file.
    """
    shapes = gpd.read_file(geojson_path)
    shapes = shapes.set_crs("EPSG:4326", allow_override=True)

    results = []

    for _, row in tqdm(shapes.iterrows(), total=shapes.shape[0], desc="Processing shapes"):
        shape_geometry = row.geometry
        date = row["date"]
        polygon_id = row.get("replicates", None)

        nc_stats = open_nc(shape_geometry, date, netcdf_path, variable)

        gc.collect()

        result_entry = {"replicates": polygon_id}
        for label, (mean, min_val, max_val) in nc_stats.items():
            result_entry[f"Cop_{variable}_{label}_mean"] = mean
            result_entry[f"Cop_{variable}_{label}_min"] = min_val
            result_entry[f"Cop_{variable}_{label}_max"] = max_val

        results.append(result_entry)

    results_df = pd.DataFrame(results)
    results_df.to_csv(output_path, index=False)











# 17/10/2025 : Extract CHL from cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D 

# 1. Convert .shp to .geojson 
# Load the file with buffer for extraction
gdf = gpd.read_file("./data/processed_data/eDNA/mtdt_5.gpkg")

# Save as GeoJSON
geojson_path = "./data/processed_data/eDNA/mtdt_5.geojson"
gdf.to_file(geojson_path, driver="GeoJSON")

print(f"GeoJSON file saved to {geojson_path}")



# 2. Make extraction (using Fct 4 and max buffer size = 0)

geojson_path="./data/processed_data/eDNA/mtdt_5.geojson"
netcdf_path="./data/raw_data/predictors/Chl/cmems_obs-oc_med_bgc-plankton_my_l4-gapfree-multi-1km_P1D_20130101-20250101.nc"
output_path="./data/processed_data/predictors/mtdt_5_CHL_exactextract.csv"


process_geojson(
    geojson_path=geojson_path,
    netcdf_path=netcdf_path,
    output_path=output_path,
    variable="CHL"  
)






#  Extract SST from SST_MED_SST_L4_NRT_OBSERVATIONS_010_004_c_V2_SST_20130101-20250101.nc 

# 2. Make extraction (using Fct 4 and max buffer size = 0)

geojson_path="./data/processed_data/eDNA/mtdt_5.geojson"
netcdf_path="./data/raw_data/predictors/SST/SST_MED_SST_L4_NRT_OBSERVATIONS_010_004_c_V2_SST_20130101-20250101.nc"
output_path="./data/processed_data/predictors/mtdt_5_SST.csv"


process_geojson(
    geojson_path=geojson_path,
    netcdf_path=netcdf_path,
    output_path=output_path,
    variable="SST"  
)






